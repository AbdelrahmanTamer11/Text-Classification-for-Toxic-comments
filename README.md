# Text-Classification-for-Toxic-comments
The main goal of toxic comment classification is to automatically  detect and flag comments that may be harmful, such as hate speech,  harassment, or abusive language. This classification enables platforms  to take appropriate actions, such as warning users, removing content,  or blocking accounts, to create a safer online environment
